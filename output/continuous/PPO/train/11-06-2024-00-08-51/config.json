{"mode": "train", "env_type": "continuous", "algorithm": "PPO", "screen_width": 16, "screen_height": 32, "num_screens": 4, "num_chains": 2, "max_chain_length": 2, "num_edges": 3, "sparsity_constant": 0.0, "num_tiers": 3, "num_branches": [1, 2, 2], "max_episode_length": 20, "env_seed": 1, "save_freq": 1000, "policy": "MlpPolicy", "lr_rate": 0.0001, "buffer_size": 10000, "learning_starts": 100, "batch_size": 32, "tau": 1.0, "gamma": 1.0, "train_freq": 4, "gradient_steps": 1, "optimize_memory_usage": false, "target_update_interval": 10000.0, "exploration_fraction": 0.1, "exploration_initial_eps": 1.0, "exploration_final_eps": 0.05, "max_grad_norm": 10.0, "verbose": 1, "agent_seed": 1, "device": "auto", "total_timesteps": 10000, "log_interval": 4, "model_name": "ppo-test", "model_dir": "", "traj_log_freq": 100, "n_epochs": 10, "n_steps": 256, "ppo_normalize_advantage": true, "ppo_target_kl": 0.01, "ddpg_buffer_size": 1000000, "ddpg_learning_starts": 100, "ddpg_batch_size": 256, "ddpg_tau": 0.005, "ddpg_gamma": 0.99, "ddpg_train_freq": 1, "ddpg_gradient_steps": 1, "ddpg_optimize_memory_usage": false}